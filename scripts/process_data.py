import pandas as pd
import os
import re
from datetime import datetime
import random 
import shutil

# --- è¨­å®šé …ç›®ï¼ˆã“ã“ã ã‘ã€ãã¾ã¡ã‚ƒã‚“ã®ç’°å¢ƒã«åˆã‚ã›ã¦ä¿®æ­£ã—ã¦ã­ï¼ï¼‰ ---
# AIReadãŒå‡ºåŠ›ã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€ (æ± ä¸Š, ä¸­å³¶, å”æœ¨ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚‹å ´æ‰€)
# ä¾‹: r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\VLM-OCR\20_æ•™å¸«ãƒ‡ãƒ¼ã‚¿\30_output_csv'
INPUT_BASE_DIR = r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\VLM-OCR\20_æ•™å¸«ãƒ‡ãƒ¼ã‚¿\30_output_csv' 

# ã‚¢ãƒ—ãƒªã®ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€ (GitHubãƒªãƒã‚¸ãƒˆãƒªã®ãƒ«ãƒ¼ãƒˆ)
# ä¾‹: r'C:\Users\User26\yoko\dev\csvRead'
APP_ROOT_DIR = r'C:\Users\User26\yoko\dev\csvRead'

# æ¤œç´¢çµæœï¼ˆB*020.csvï¼‰ã®ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€
# ä¾‹: C:\Users\User26\yoko\dev\csvRead\filtered_originals
SEARCH_RESULT_OUTPUT_BASE_DIR = os.path.join(APP_ROOT_DIR, 'filtered_originals')

# åŠ å·¥å¾Œã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€
# ä¾‹: C:\Users\User26\yoko\dev\csvRead\processed_output
PROCESSED_OUTPUT_BASE_DIR = os.path.join(APP_ROOT_DIR, 'processed_output') 

# ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€
# ä¾‹: C:\Users\User26\yoko\dev\csvRead\master_data
MASTER_DATA_DIR = os.path.join(APP_ROOT_DIR, 'master_data')

# PostgreSQLã®æœ€çµ‚å½¢ã«å¿…è¦ãªå…¨ã¦ã®ã‚«ãƒ©ãƒ åã‚’ãƒªã‚¹ãƒˆã§å®šç¾©
FINAL_POSTGRE_COLUMNS = [
    'ocr_result_id', 'page_no', 'id', 'jgroupid_string', 'cif_number', 'settlement_at',
    'maker_name_original', 'maker_name', 'maker_com_code',
    'issue_date_rightside_date', 'issue_date',
    'due_date_rightside_date', 'due_date',
    'balance_rightside', 'balance',
    'payment_bank_name_rightside', 'payment_bank_name',
    'payment_bank_branch_name_rightside', 'payment_bank_branch_name',
    'description_rightside', 'description'
]

# --- å„CSVãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã”ã¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ã‚’å®šç¾© ---
# ã“ã‚ŒãŒExcelãŒå†…éƒ¨çš„ã«æŒã¤ã€Œå¤‰æ›ãƒ¬ã‚·ãƒ”ã€ã‚’Pythonã§æ˜ç¤ºçš„ã«å®šç¾©ã™ã‚‹éƒ¨åˆ†

# å„ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ã¯ (PostgreSQLã®ç›®æ¨™ã‚«ãƒ©ãƒ å : å…ƒã®CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼å ã¾ãŸã¯ åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹) ã®å½¢å¼
# maker_name, issue_date, due_date, balance, payment_bank_name, payment_bank_branch_name, description_rightside, description
# ã‚’ä¸­å¿ƒã«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å®šç¾©ã—ã€ã“ã‚Œã‚‰ã®æ´¾ç”Ÿã‚«ãƒ©ãƒ ã‚‚é©åˆ‡ã«åŸ‹ã‚ã‚‹ã€‚

# 1. æ‰‹å½¢æƒ…å ±å½¢å¼ã®CSV (ä¾‹: "æŒ¯å‡ºäºº", "æŒ¯å‡ºå¹´æœˆæ—¥", "é‡‘é¡" ãªã©)
HAND_BILL_MAPPING_DICT = {
    'maker_name': 'æŒ¯å‡ºäºº',
    'issue_date': 'æŒ¯å‡ºå¹´æœˆæ—¥',
    'due_date': 'æ”¯æ‰•æœŸæ—¥',
    'payment_bank_name': 'æ”¯æ‰•éŠ€è¡Œåç§°',
    'payment_bank_branch_name': 'æ”¯æ‰•éŠ€è¡Œæ”¯åº—å',
    'balance': 'é‡‘é¡',
    'description_rightside': 'å‰²å¼•éŠ€è¡ŒååŠã³æ”¯åº—åç­‰', 
    'description': 'æ‘˜è¦' 
}

# 2. è²¡å‹™è«¸è¡¨ (å‹˜å®šç§‘ç›®ã¨é‡‘é¡) å½¢å¼ã®CSV (ä¾‹: "account", "amount_0", "amount_1" ãªã©)
#    - PostgreSQLã®ã‚«ãƒ©ãƒ ã«æ„å‘³çš„ã«åˆã‚ãªã„ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã‚‹ã“ã¨ã‚’è¨±å®¹ã—ã€å¯èƒ½ãªé™ã‚ŠåŸ‹ã‚ã‚‹
FINANCIAL_STATEMENT_MAPPING_DICT = {
    'maker_name': 'account', # å‹˜å®šç§‘ç›®ã‚’maker_nameã«
    'issue_date': 'amount_0', 
    'balance': 'amount_0',    
    'due_date': 'amount_1',   
    'description': 'amount_2' 
}

# 3. å€Ÿå…¥é‡‘æ˜ç´°å½¢å¼ã®CSV (ä¾‹: "å€Ÿå…¥å…ˆåç§°(æ°å)", "æœŸæœ«ç¾åœ¨é«˜" ãªã©)
#    - ã“ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã¯ã€å…ƒã®CSVã«ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹
LOAN_DETAILS_MAPPING_DICT = {
    'maker_name': 'å€Ÿå…¥å…ˆåç§°(æ°å)',
    'issue_date': 'å€Ÿå…¥å…ˆæ‰€åœ¨åœ°(ä½æ‰€)', 
    'balance': 'æœŸæœ«ç¾åœ¨é«˜',           
    'description_rightside': 'æœŸä¸­ã®æ”¯æ‰•åˆ©å­é¡', 
    'description': 'åˆ©ç‡',            
}

# 4. ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã®CSV (æœ€åˆã®è¡Œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãŒå§‹ã¾ã‚‹)
#    - ãƒãƒƒãƒ”ãƒ³ã‚°å…ƒã¯åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (0å§‹ã¾ã‚Š)
#    - ã“ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã¯ã€ç‰¹å®šã®ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ã€Œæ±ç”¨ã€ãƒãƒƒãƒ”ãƒ³ã‚°
NO_HEADER_MAPPING_DICT = {
    'maker_name': 0, 
    'issue_date': 1, 
    'due_date': 2,   
    'payment_bank_name': 3, 
    'payment_bank_branch_name': 4, 
    'balance': 5,    
    'description_rightside': 6, 
    'description': 7, 
}


# --- é–¢æ•°å®šç¾©ï¼ˆã“ã®éƒ¨åˆ†ã¯å¤‰æ›´ã—ãªã„ã§ã­ï¼ï¼‰ ---
# ocr_result_id ã®é€šã—ç•ªå·ã‚’ä¿æŒã™ã‚‹ãŸã‚ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
# ã“ã®å¤‰æ•°ã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œé–‹å§‹æ™‚ã«ä¸€åº¦ã ã‘åˆæœŸåŒ–ã•ã‚Œã‚‹
current_ocr_id_sequence = 0 

# maker_com_code ã®æ¡ç•ªã‚’ä¿æŒã™ã‚‹ãŸã‚ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
maker_name_to_com_code_map = {}
next_maker_com_code_val = 1 # 001ã‹ã‚‰é–‹å§‹

# jgroupid_string ã®æ¡ç•ªã‚’ä¿æŒã™ã‚‹ãŸã‚ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
current_jgroupid_index = 0 # jgroupidãƒã‚¹ã‚¿ãƒªã‚¹ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦ä½¿ç”¨
jgroupid_values_from_master = [] # jgroupidãƒã‚¹ã‚¿ã‹ã‚‰èª­ã¿è¾¼ã‚“ã å€¤ã‚’æ ¼ç´


def get_next_ocr_id():
    """ocr_result_idã‚’1ã‹ã‚‰9999ã¾ã§ã®è‡ªå‹•æ¡ç•ªã§å–å¾—ã™ã‚‹ï¼ˆ4æ¡ã§çµ‚ã‚ã‚‹ï¼‰"""
    global current_ocr_id_sequence 
    current_ocr_id_sequence += 1
    # 1ã‹ã‚‰9999ã¾ã§ã®é€£ç•ªã‚’4æ¡ã§ã‚¼ãƒ­åŸ‹ã‚ã€‚9999ã‚’è¶…ãˆãŸã‚‰0001ã«æˆ»ã‚‹ï¼ˆExcelã®ã€Œè¶…ãˆãªã„ã€è¦ä»¶è§£é‡ˆï¼‰
    # IDå…¨ä½“ã‚’4æ¡ã«ã™ã‚‹ï¼ˆExcelã®ã€Œ4æ¡ã§çµ‚ã‚ã‚‹ã€ã¨ã€Œ1ã‹ã‚‰æ¡ç•ªã€ã‚’å„ªå…ˆï¼‰
    return str(current_ocr_id_sequence % 10000).zfill(4)

def get_next_jgroupid_string():
    """jgroupid_stringã‚’jgroupidãƒã‚¹ã‚¿ã‹ã‚‰é€£ç•ªã§å–å¾—ã™ã‚‹ï¼ˆ1ã‹ã‚‰93ã‚’ãƒ«ãƒ¼ãƒ—ï¼‰"""
    global current_jgroupid_index 
    global jgroupid_values_from_master 

    # jgroupidãƒã‚¹ã‚¿ãŒç©ºã§ãªã‘ã‚Œã°ã€ãã®ãƒªã‚¹ãƒˆã‹ã‚‰å–å¾—
    if jgroupid_values_from_master:
        # ãƒªã‚¹ãƒˆã®é•·ã•ã«å¿œã˜ã¦ãƒ«ãƒ¼ãƒ—ã—ã€é€£ç•ªã§å–å¾—
        jgroupid_val = jgroupid_values_from_master[current_jgroupid_index % len(jgroupid_values_from_master)]
        current_jgroupid_index += 1
        return str(jgroupid_val).zfill(3) # 3æ¡ã§ã‚¼ãƒ­åŸ‹ã‚ã‚’ä¿è¨¼
    else:
        # ãƒã‚¹ã‚¿ãŒèª­ã¿è¾¼ã‚ãªã‹ã£ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä»¥å‰ã®å‹•ä½œï¼‰
        return "000" # ãƒã‚¹ã‚¿ãŒèª­ã‚ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

def get_maker_com_code_for_name(maker_name):
    """
    maker_nameã«åŸºã¥ã„ã¦3æ¡ã®ä¼šç¤¾ã‚³ãƒ¼ãƒ‰ã‚’æ¡ç•ªãƒ»å–å¾—ã™ã‚‹ã€‚
    åŒã˜maker_nameã«ã¯åŒã˜ã‚³ãƒ¼ãƒ‰ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã€‚
    """
    global maker_name_to_com_code_map 
    global next_maker_com_code_val 

    if maker_name in maker_name_to_com_code_map:
        return maker_name_to_com_code_map[maker_name]
    else:
        # æ–°ã—ã„3æ¡ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
        new_code = str(next_maker_com_code_val).zfill(3)
        maker_name_to_com_code_map[maker_name] = new_code
        next_maker_com_code_val += 1
        return new_code


def process_universal_csv(input_filepath, processed_output_base_dir, input_base_dir, 
                        maker_master_df, # jgroupid_master_df_param ã¯ä½¿ã‚ãªã„ã®ã§å‰Šé™¤
                        final_postgre_columns_list, no_header_map, hand_bill_map, financial_map, loan_map): # å¼•æ•°ã‹ã‚‰jgroupid_master_df_paramã‚’å‰Šé™¤
    """
    å…¨ã¦ã®AIReadå‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€çµ±ä¸€ã•ã‚ŒãŸPostgreSQLå‘ã‘ã‚«ãƒ©ãƒ å½¢å¼ã«å¤‰æ›ã—ã¦å‡ºåŠ›ã™ã‚‹é–¢æ•°ã€‚
    CSVã®ç¨®é¡ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼å†…å®¹ï¼‰ã‚’åˆ¤åˆ¥ã—ã€ãã‚Œãã‚Œã«å¿œã˜ãŸãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨ã™ã‚‹ã€‚
    """
    df_original = None
    file_type = "ä¸æ˜" # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’åˆ¤åˆ¥ã™ã‚‹ãŸã‚ã®å¤‰æ•°

    try:
        # 1. ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€åˆã®æ•°è¡Œã‚’èª­ã¿è¾¼ã¿ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã®æœ‰ç„¡ã¨å†…å®¹ã‚’åˆ¤åˆ¥
        first_line_content = ""
        
        # è©¦è¡Œã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒªã‚¹ãƒˆ (UTF-8ã‚’å„ªå…ˆ)
        encodings_to_try = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932']

        for enc in encodings_to_try:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’æ–‡å­—åˆ—ã¨ã—ã¦èª­ã¿è¾¼ã¿ã€ãƒ˜ãƒƒãƒ€ãƒ¼åˆ¤å®šã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚’è¡Œã†
                with open(input_filepath, 'r', encoding=enc, newline='') as f_read_all:
                    all_lines_from_file = f_read_all.readlines()
                
                if not all_lines_from_file:
                    raise ValueError("ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™ã€‚")
                
                first_line_content = all_lines_from_file[0].strip()

                # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è‡ªå‹•åˆ¤åˆ¥
                # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’pandasã«æ¸¡ã™ã‹ã©ã†ã‹ã‚’æ±ºå®š
                read_header = 0 # default for header exists
                
                if ('"æŒ¯å‡ºäºº"' in first_line_content) or ('æŒ¯å‡ºäºº,' in first_line_content):
                    file_type = "æ‰‹å½¢æƒ…å ±"
                elif ('"account"' in first_line_content) or ('account,' in first_line_content):
                    file_type = "è²¡å‹™è«¸è¡¨"
                elif ('"å€Ÿå…¥å…ˆåç§°(æ°å)"' in first_line_content) or ('å€Ÿå…¥åç§°(æ°å),' in first_line_content): # 'å€Ÿå…¥åç§°(æ°å)'ã®å¾Œã«ã‚«ãƒ³ãƒãŒãªã„ã‚±ãƒ¼ã‚¹ã«å¯¾å¿œ
                    file_type = "å€Ÿå…¥é‡‘æ˜ç´°"
                else:
                    file_type = "æ±ç”¨ãƒ‡ãƒ¼ã‚¿_ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—"
                    read_header = None # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãªã„ã®ã§ã€æœ€åˆã®è¡Œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦èª­ã¿è¾¼ã‚€


                df_original = pd.read_csv(input_filepath, encoding=enc, header=read_header)
                print(f"  ãƒ•ã‚¡ã‚¤ãƒ« {os.path.basename(input_filepath)} ã‚’ {enc} ({file_type}, header={read_header}) ã§èª­ã¿è¾¼ã¿æˆåŠŸã€‚")
                break # èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
            except Exception as e_inner: # èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯æ¬¡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
                print(f"  ãƒ•ã‚¡ã‚¤ãƒ« {os.path.basename(input_filepath)} ã‚’ {enc} ã§èª­ã¿è¾¼ã¿å¤±æ•—ã€‚åˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°/ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®šã‚’è©¦ã—ã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼: {e_inner}")
                df_original = None 
                continue 

        if df_original is None or df_original.empty:
            raise ValueError(f"ãƒ•ã‚¡ã‚¤ãƒ« {os.path.basename(input_filepath)} ã‚’ã©ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®šã§ã‚‚èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        print(f"  ãƒ•ã‚¡ã‚¤ãƒ« {os.path.basename(input_filepath)} ã¯ '{file_type}' ã¨ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆ{input_filepath}ï¼‰: CSVèª­ã¿è¾¼ã¿ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¤åˆ¥ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return

    # --- ãƒ‡ãƒ¼ã‚¿åŠ å·¥å‡¦ç† ---
    # df_processed ã‚’å…ˆã«åˆæœŸåŒ–ã—ã€PostgreSQLã®æœ€çµ‚ã‚«ãƒ©ãƒ æ§‹é€ ã‚’æŒã¤ã‚ˆã†ã«ã™ã‚‹
    df_processed = pd.DataFrame(columns=final_postgre_columns_list)
    
    # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿è¡Œã®ã¿ã‚’å‡¦ç†å¯¾è±¡ã¨ã™ã‚‹
    # header=0ã§èª­ã¿è¾¼ã‚“ã å ´åˆã¯ df_originalã¯æ—¢ã«ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒé™¤ã‹ã‚Œã¦ã„ã‚‹ã€‚
    # header=Noneã§èª­ã¿è¾¼ã‚“ã å ´åˆï¼ˆæ±ç”¨ãƒ‡ãƒ¼ã‚¿_ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ï¼‰ã¯ã€df_originalã®0è¡Œç›®ãŒãƒ˜ãƒƒãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ãªã®ã§ã€ãã‚Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚
    df_data_rows = None
    if file_type == "æ±ç”¨ãƒ‡ãƒ¼ã‚¿_ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—":
        df_data_rows = df_original.iloc[1:].copy() # æœ€åˆã®è¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã‚¹ã‚­ãƒƒãƒ— (header=Noneã§èª­ã‚“ã å ´åˆ)
    else: # æ‰‹å½¢æƒ…å ±, è²¡å‹™è«¸è¡¨, å€Ÿå…¥é‡‘æ˜ç´° (header=0ã§èª­ã¿è¾¼ã¾ã‚ŒãŸã‚‚ã®)
        df_data_rows = df_original.iloc[0:].copy() # df_originalè‡ªä½“ãŒæ—¢ã«ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒé™¤ã‹ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãªã®ã§ã€å…¨ã¦ã‚’ã‚³ãƒ”ãƒ¼

    # df_data_rows ãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
    if df_data_rows.empty:
        print(f"  è­¦å‘Š: ãƒ•ã‚¡ã‚¤ãƒ« {os.path.basename(input_filepath)} ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿è¡ŒãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€åŠ å·¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’ä¸­æ–­

    num_rows_to_process = len(df_data_rows) # å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿è¡Œæ•°

    # --- å…±é€šé …ç›® (PostgreSQLã®ã‚°ãƒªãƒ¼ãƒ³ã®è¡¨ã®å·¦å´ã«æ¥ã‚‹ã€è‡ªå‹•ç”Ÿæˆé …ç›®) ã®ç”Ÿæˆ ---
    # ocr_result_id: 1ã‹ã‚‰ã®è‡ªå‹•æ¡ç•ªã§ã€4æ¡ã§çµ‚ã‚ã‚‹
    ocr_result_id_val = get_next_ocr_id() 
    df_processed['ocr_result_id'] = [ocr_result_id_val] * num_rows_to_process 


    # page_no: ä½•ã§ã‚‚ã‚ˆã„ï¼ˆ1ã§å›ºå®šï¼‰ã®è¦ä»¶ã«å¾“ã†
    df_processed['page_no'] = [1] * num_rows_to_process 

    # id: ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­ã§ã‚«ã‚¦ãƒ³ãƒˆã‚¢ãƒƒãƒ— (å„è¡Œã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªID)
    df_processed['id'] = range(1, num_rows_to_process + 1)

    # jgroupid_string: jgroupid_masterã‹ã‚‰é€£ç•ªã§å–å¾—
    jgroupid_string_val = get_next_jgroupid_string() # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚‰å–å¾—
    df_processed['jgroupid_string'] = [jgroupid_string_val] * num_rows_to_process

    # cif_number: ãƒ©ãƒ³ãƒ€ãƒ ãªæ•°å­—åˆ—ï¼ˆ6æ¡ã®ä¾‹ï¼‰
    cif_number_val = str(random.randint(100000, 999999))
    df_processed['cif_number'] = [cif_number_val] * num_rows_to_process

    # settlement_at: yyyyMMå½¢å¼ã§ä½•ã§ã‚‚ã‚ˆã„
    settlement_at_val = datetime.now().strftime('%Y%m') # YYYYMMå½¢å¼
    df_processed['settlement_at'] = [settlement_at_val] * num_rows_to_process

    # PostgreSQLã®æœ€çµ‚å½¢ã«å¿…è¦ãªå…¨ã¦ã®ã‚«ãƒ©ãƒ ã‚’ç©ºã§åˆæœŸåŒ–
    # final_postgre_columns_list ã¯å¼•æ•°ã¨ã—ã¦æ¸¡ã•ã‚Œã‚‹
    
    # è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸ6é …ç›®ä»¥å¤–ã®PostgreSQLã‚«ãƒ©ãƒ ã‚’ç©ºã§åˆæœŸåŒ–
    for pg_col in final_postgre_columns_list[6:]: 
        df_processed[pg_col] = '' 

    # --- å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨ ---
    
    # ä½¿ç”¨ã™ã‚‹ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ã‚’æ±ºå®š
    mapping_to_use = {}
    if file_type == "æ‰‹å½¢æƒ…å ±":
        mapping_to_use = hand_bill_map
    elif file_type == "è²¡å‹™è«¸è¡¨": 
        mapping_to_use = financial_map
    elif file_type == "å€Ÿå…¥é‡‘æ˜ç´°": 
        mapping_to_use = loan_map
    else: # "æ±ç”¨ãƒ‡ãƒ¼ã‚¿_ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—"
        mapping_to_use = no_header_map


    # df_processed ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´
    for pg_col_name, src_ref in mapping_to_use.items():
        if isinstance(src_ref, str): # å…ƒãŒãƒ˜ãƒƒãƒ€ãƒ¼åã®å ´åˆ
            if src_ref in df_data_rows.columns: # df_data_rows ã®ã‚«ãƒ©ãƒ åã‚’ãƒã‚§ãƒƒã‚¯
                df_processed[pg_col_name] = df_data_rows[src_ref].fillna('').astype(str).values 
            # else: å…ƒã®CSVã«ãƒ˜ãƒƒãƒ€ãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã« (åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã®ã§ä½•ã‚‚ã—ãªã„)
        elif isinstance(src_ref, int): # å…ƒãŒåˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å ´åˆ
            if src_ref < df_data_rows.shape[1]:
                df_processed[pg_col_name] = df_data_rows.iloc[:, src_ref].fillna('').astype(str).values 
            # else: å…ƒã®CSVã«åˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã« (åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã®ã§ä½•ã‚‚ã—ãªã„)
        # else: ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ãŒä¸æ­£ãªå ´åˆã‚‚ã€ã™ã§ã«åˆæœŸåŒ–æ¸ˆã¿ãªã®ã§ä½•ã‚‚ã—ãªã„


    # --- Excelé–¢æ•°ç›¸å½“ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’é©ç”¨ï¼ˆæ´¾ç”Ÿã‚«ãƒ©ãƒ ã®ç”Ÿæˆï¼‰ ---

    # maker_name_original ã¯ maker_name ã¨åŒã˜
    df_processed['maker_name_original'] = df_processed['maker_name'].fillna('').astype(str)
    
    # maker_com_code (æ–°ã—ã„3æ¡è‡ªå‹•æ¡ç•ªãƒ­ã‚¸ãƒƒã‚¯)
    # å„è¡Œã®maker_nameã«å¯¾ã—ã¦ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»å–å¾—
    df_processed['maker_com_code'] = df_processed['maker_name'].apply(get_maker_com_code_for_name)

    # issue_date_rightside_date, due_date_rightside_date, balance_rightside ãªã©
    # Excelã®ä¾‹ã ã¨ãã‚Œãã‚Œå¯¾å¿œã™ã‚‹ã‚«ãƒ©ãƒ ã¨åŒã˜å€¤
    df_processed['issue_date_rightside_date'] = df_processed['issue_date'].fillna('').astype(str)
    df_processed['due_date_rightside_date'] = df_processed['due_date'].fillna('').astype(str)
    df_processed['balance_rightside'] = df_processed['balance'].fillna('').astype(str)
    df_processed['payment_bank_name_rightside'] = df_processed['payment_bank_name'].fillna('').astype(str)
    df_processed['payment_bank_branch_name_rightside'] = df_processed['payment_bank_branch_name'].fillna('').astype(str)
    # description_rightside ã¯ description ã¨åŒã˜ (ã‚‚ã—Excelã§ãã†ãªã‚‰)
    # description_rightsideã¨descriptionã¯åˆ¥ã€…ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸã®ã§ã€ãã®ã¾ã¾ã€‚

    # æœ€çµ‚çš„ãªåˆ—ã®é †åºã¯PostgreSQLã®ç›®æ¨™å½¢å¼ã«åˆã‚ã›ã‚‹ (df_processedã¯æ—¢ã«ã“ã®ã‚«ãƒ©ãƒ é †ã§ä½œæˆã•ã‚Œã¦ã„ã‚‹)
    # reindexã¯ä¸è¦ã€‚åˆæœŸåŒ–ã§ã‚«ãƒ©ãƒ é †ã¯ç¢ºä¿æ¸ˆã¿ã€‚

    # --- ä¿å­˜å‡¦ç† ---
    # å‡ºåŠ›å…ˆã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’å…ƒã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã«åˆã‚ã›ã¦ä½œæˆ
    relative_path_to_file = os.path.relpath(input_filepath, input_base_dir)
    relative_dir_to_file = os.path.dirname(relative_path_to_file)
    processed_output_sub_dir = os.path.join(processed_output_base_dir, relative_dir_to_file)
    os.makedirs(processed_output_sub_dir, exist_ok=True)

    # åŠ å·¥å¾Œã®CSVã‚’ä¿å­˜
    processed_output_filename = os.path.basename(input_filepath).replace('.csv', '_processed.csv')
    processed_output_filepath = os.path.join(processed_output_sub_dir, processed_output_filename)
    df_processed.to_csv(processed_output_filepath, index=False, encoding='utf-8-sig')

    print(f"âœ… åŠ å·¥å®Œäº†: {input_filepath} -> {processed_output_filepath}")

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆã“ã®éƒ¨åˆ†ã‚‚å¤‰æ›´ã—ãªã„ã§ã­ï¼ï¼‰ ---
if __name__ == "__main__":
    print(f"--- å‡¦ç†é–‹å§‹: {datetime.now()} ---")

    # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ
    os.makedirs(PROCESSED_OUTPUT_BASE_DIR, exist_ok=True) 

    # ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    MASTER_DATA_DIR = os.path.join(APP_ROOT_DIR, 'master_data') # APP_ROOT_DIR ã‹ã‚‰ãƒ‘ã‚¹ã‚’æ§‹ç¯‰

    # maker_master.csv ã‚’èª­ã¿è¾¼ã‚€
    maker_master_filepath = os.path.join(MASTER_DATA_DIR, 'master.csv') # <<-- ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ 'master.csv' ã«ä¿®æ­£æ¸ˆã¿ï¼
    maker_master_df = pd.DataFrame() 
    if os.path.exists(maker_master_filepath):
        try:
            maker_master_df = pd.read_csv(maker_master_filepath, encoding='utf-8')
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: master.csv ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}")
            maker_master_df = pd.DataFrame({'ä¼šç¤¾å': [], 'ä¼šç¤¾ã‚³ãƒ¼ãƒ‰': []}) # ç©ºã®DataFrameã§ç¶™ç¶š
    else:
        print(f"âš ï¸ è­¦å‘Š: master.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {maker_master_filepath}")
        maker_master_data = {
            'ä¼šç¤¾å': ['(æ ª)åŒæ–‡ç¤¾å°åˆ·', '(æ ª)å¤ªå¹³å°åˆ·ç¤¾', '(æ ª)ãƒªãƒ¼ãƒ–ãƒ«ãƒ†ãƒƒã‚¯', 'æ—¥æœ¬ãƒã‚¤ã‚³ãƒ (æ ª)', '(æ ª)æ–°å¯¿å ‚', 'æ‰‹æŒæ‰‹å½¢è¨ˆ', 'å‰²å¼•æ‰‹å½¢è¨ˆ', '(æ ª)ã‚·ãƒ¼ãƒ•ã‚©ãƒ¼ã‚¹'],
            'ä¼šç¤¾ã‚³ãƒ¼ãƒ‰': ['4380946945', '9138429316', '2578916640', '5408006886', '0668992415', '9443492307', '4417864013', '7398659210']
        }
        maker_master_df = pd.DataFrame(maker_master_data)

    # jgroupid_master.csv ã‚’èª­ã¿è¾¼ã‚€
    jgroupid_master_filepath = os.path.join(MASTER_DATA_DIR, 'jgroupid_master.csv')
    
    if os.path.exists(jgroupid_master_filepath): 
        try:
            # jgroupid_master.csv ã¯ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã§ã€1è¡Œç›®ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãŒå§‹ã¾ã‚‹ã“ã¨ã‚’æƒ³å®š
            df_jgroupid_temp = pd.read_csv(jgroupid_master_filepath, encoding='utf-8', header=None)
            
            # 0åˆ—ç›®ï¼ˆæœ€åˆã®åˆ—ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦å–å¾—ã—ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«æ ¼ç´
            if not df_jgroupid_temp.empty and df_jgroupid_temp.shape[1] > 0:
                jgroupid_values_from_master = df_jgroupid_temp.iloc[:, 0].astype(str).tolist()
                # ãƒªã‚¹ãƒˆãŒç©ºã§ãªã„ã‹ç¢ºèª
                if not jgroupid_values_from_master:
                    raise ValueError("jgroupid_master.csv ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã—ãŸãŒã€ãƒªã‚¹ãƒˆãŒç©ºã§ã™ã€‚")
            else:
                raise ValueError("jgroupid_master.csv ãŒç©ºã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: jgroupid_master.csv ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¾ãŸã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®1-93ãƒªã‚¹ãƒˆã§ç¶™ç¶š
            jgroupid_values_from_master = [str(i).zfill(3) for i in range(1, 94)] 
    else:
        print(f"âš ï¸ è­¦å‘Š: jgroupid_master.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {jgroupid_master_filepath}")
        # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹ç¤ºï¼‰
        jgroupid_values_from_master = [str(i).zfill(3) for i in range(1, 94)] 


    # INPUT_PROCESSED_DIR ã¯ filter_and_copy_csv.py ãŒå‡ºåŠ›ã—ãŸãƒ•ã‚©ãƒ«ãƒ€
    INPUT_PROCESSED_DIR = os.path.join(APP_ROOT_DIR, 'filtered_originals') 

    # INPUT_PROCESSED_DIRå†…ã®å…¨ã¦ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    for root, dirs, files in os.walk(INPUT_PROCESSED_DIR):
        for filename in files:
            # _processed.csv ãŒä»˜ã„ã¦ã„ãªã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å‡¦ç†å¯¾è±¡ã¨ã™ã‚‹
            if filename.lower().endswith('.csv') and not filename.lower().endswith('_processed.csv'): 
                input_filepath = os.path.join(root, filename)
                print(f"\n--- å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {input_filepath} ---")

                # åŠ å·¥å‡¦ç†ã‚’å®Ÿè¡Œ
                process_universal_csv(input_filepath, PROCESSED_OUTPUT_BASE_DIR, INPUT_PROCESSED_DIR, 
                                    maker_master_df, 
                                    FINAL_POSTGRE_COLUMNS, NO_HEADER_MAPPING_DICT, HAND_BILL_MAPPING_DICT, 
                                    FINANCIAL_STATEMENT_MAPPING_DICT, LOAN_DETAILS_MAPPING_DICT)

    print(f"\nğŸ‰ å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®åŠ å·¥å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼ ({datetime.now()}) ğŸ‰")
    